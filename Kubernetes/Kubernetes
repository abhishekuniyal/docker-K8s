

kubectl port-forward <pod_id> 8080:8080 -n <namespac>  : to connect to your pod from ur local machine
now connect 127.0.0.1:8080

*****Kubernetes**************
-is an Orchestration technology
-to manage 100's of containers.
-has HA ,Scalabilty and Disaster Recovery

Pod:	abstraction over the container.(so that k8s become indepenedent of container tchnology). now conta could be of docker/Rkt/etc
	is ephimeral i.e can die and new dynamic IP will be assigned to this new POd. 
	This is problem as you were working on a differ Ip and sudenly new Ip is assigned. This issue is resolved with the permanent Ip 	  solution called Service:

Service: Permannent Ip address can be attached to Pod.
	Lifecycle of pod& service is NOT connected . so even pod dies service *which was connected with outer services is not affected)
	Service also works as a LoadBalancer. if3 instances of same pod is running service to decide which one to call
Ingress: before reaching to service(As Db service u wont want to expose) , request will be reached to INGRESS (http/https)
confgimaps/secreste:
Volumes: as K8s doesnt manage the Data persistent, we are resposnsible to for that,

Deployment: Blueprint for pods with replicas(how many pods to instantiate)
	    abstraction over the pods
Statefull sets: Now can i start multiple replicas of DB pod through deployment. NO, as DB has states
		Statefull sets can scale up-down (replications) as finally data is written to a single DB in a manner the data should not 			become incosistent. this all is handlled by statefull sets.
		One of common approach to not use DB in K8 cluster and access DB from outside k8 cluster.


***************Kubernetes Architecture************************

Master						Worker Nodes
----------------------------------------------------------------------------------------------------------------------------------------------
*ApiServer: 				  *Kublet    : responsible for sceduling the pods
*Scheduler				  *Kube-proxy : responsible for forwarding the request (from service) to respective pods in an *Controller manager						intelligent manner
*etcd 					  *Container Runtime : Docker /Rkt

-----------------------------------------------------------------------------------------------------------------------------------
|Schedule new Pod => API server => Scheduler =>where to put pod => Kublet
|If any pod dies CONTROLLER Manager => Scheduler =>where to put pod => Kublet
|----------------------------------------------------------------------------------------------------------------------------------

*Kublet    : responsible for sceduling the pods
*Kube-proxy : responsible for forwarding the request (from service) to respective pods in an intelligent manner
*Container Runtime : Docker /Rkt

*ApiServer: Cluster Gateway
	    Acts as a gatkeeper Authentication
	    whenever we want to create pod/deployment service etc will have to go through Apiserver.
	    Every client (cmd line,ui,api) will have to connect with Api server
*Scheduler: Scheduler to decide which Node to put the newly request for pod sent by ApiServer
	    Scheduler just decide on which Node new Pod should be Schedule ==> But actually KUBLET to actually schedule/starts the pod
*Controller Manager: Detect cluster state changes like crashing of pods
		     request to starts a new pod
*etcd : key-value Databases
	cluster brain


Layers of abstraction for Deployment is below
   * Deployment manages a ReplicaSet
   * ReplicaSet manages all the pods
   * Pod is an abstraction of container
   * Container

So, everything below the Deployment is handled by Kubernetes. we just have to work with Deployment
kubectl edit deployment <deployment-name> can give you complete information

kubectl logs <deployment_name>  ==> to see the complete logs
kubectl describe pod <pod_name> ==> to see the state change from started to running
kubectl exec -it <podname> --bin/bash	==> inside 

kubectl delete deployment <deploymentname>  => will delete pod and replpicaset
kubectl get pods -o wide 

kubectl apply -f <fie_name>.yaml

kubect get secrets

kubectl get all | grep iclear

****Services*****
external: using LoadBalancer or NodePort service : noeport : 3000-32767
internal: ClusterIp service

****K8 namespaces**************
cluster inside a cluster
default name spaces:
 kubectls get namespace
  kube-system : this nmaespace has system process, master and kubectl processes. we DONOT create or Modify this
  kube-pulic  : this nmaespace has publically accessible data. It has a config map which contains cluster info and can be get without any 			authentication. e.g kubectl get cluster-info => gives info w/o any authentication
  kube-node-lease: this nmaespace contains heartBEat of the nodes. So, each node has associated leaseObject in namespace. determine 			   availability of the node
  default:   resources we created are located here.

creating new namespace: kubectl create namespace my-namespace. can be created vua yaml filejustadd namespace:my-namespace under the "metadata" tag

shared services from other namespaces has to be referenced with my_db_servce.database (serice.namespace)
Volumes and Node cant be restricted to a single namespace, tey will be available globally (can check kubect api-resources --namespaced=false

*******************INGRESS***************************

But as external Service exposed directly to external world, we cant use this in production env .
we use INGRESS for this.

So ingress will redirect calls from outerworld to internal SERVICE(clusterip) based on the ingress rules
host : in ingress file must map the ENTRYPOINT IP (in our cse nginx server OUTSIDE kubernets cluster)

INgress :
Ingress Controller: Implementation for Ingresss
		     Evaluate and process ingress rule
 		     need to install in kubernetes cluster
		     Entry point in the cluster

Also, u have to map dashboard.com host with the IP
once u create this ingress kubectl apply -f ingress.yaml
and get the IP assigned . that IP needs to be configured with the host

use sudo vim /etc/hosts and add the key value

Default BE service: if path not found can be redirected to default BE service for common messgae . u can cree a defalt BE nd defau;t pod for the same.sudo vim /etc/hosts
   

http in ingress resource means ==> the communication from ingresss controller to Service (shouldnt be confused with http://www.dash.com)

Configuring TLS certificate in ingress
communication between ingress controller and service can be secured and move to TLS using certificates

steps to add tls in ingress
   add tls in specs and add secretName
   create secret which contains tls certificate and type as tls


*********************************************Helm******************************************
Helm is a package manager for kubernetes
   to package yaml files and distribute them in public and private repositories

some commonly used apps like elk,my-sql, prometheus etc have helm charts available , so that u dont have to write and manage yaml for those.
helm hub
helm private registry
helm chart structure
myChart/
  Chart.yaml
  values.yaml
  charts/
  templates/

helm install <chartname>
clien - Tiller (removed in helm 3)

******************************************Kubernetes VOLUMES********************************

* persistent Volume
  - acluster resource
  -

* Persistent Volume Claim
  pod -> has volumes and PVC name --> connects to PVC ---> connects to PV

* Storage class:
